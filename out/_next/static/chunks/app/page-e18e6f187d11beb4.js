(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[931],{999:function(e,t,i){Promise.resolve().then(i.bind(i,45616)),Promise.resolve().then(i.bind(i,31618)),Promise.resolve().then(i.bind(i,77341))},45616:function(e,t,i){"use strict";i.r(t),i.d(t,{default:function(){return f}});var n=i(2070),a=i(30814),o=i(85078),s=i(79752),r=i(4852),l=i(82049),c=i(37074),d=i(18034),m=i(26264),u=i(5382),p=i(24245),h=i.n(p);let g=[{icon:(0,n.jsx)(r.Z,{className:"h-8 w-8"}),name:"Machine Learning",color:"text-purple-400"},{icon:(0,n.jsx)(l.Z,{className:"h-8 w-8"}),name:"Data Engineering",color:"text-blue-500"},{icon:(0,n.jsx)(c.Z,{className:"h-8 w-8"}),name:"Analytics",color:"text-green-400"},{icon:(0,n.jsx)(d.Z,{className:"h-8 w-8"}),name:"Cloud",color:"text-sky-400"},{icon:(0,n.jsx)(m.Z,{className:"h-8 w-8"}),name:"MLOps",color:"text-red-400"},{icon:(0,n.jsx)(u.Z,{className:"h-8 w-8"}),name:"DevOps",color:"text-orange-400"}];function f(){let[e,t]=(0,a.useState)(0);return(0,a.useEffect)(()=>{let e=setInterval(()=>{t(e=>(e+1)%g.length)},3e3);return()=>clearInterval(e)},[]),(0,n.jsxs)("div",{className:"relative overflow-hidden",children:[(0,n.jsx)("div",{className:"absolute inset-0 bg-gradient-to-b from-background to-background/60 z-10"}),(0,n.jsx)("div",{className:"absolute inset-0 opacity-5",children:(0,n.jsx)("div",{className:"absolute inset-0 bg-[linear-gradient(to_right,#80808012_1px,transparent_1px),linear-gradient(to_bottom,#80808012_1px,transparent_1px)] bg-[size:24px_24px]"})}),(0,n.jsx)("div",{className:"container relative z-20 pt-24 pb-16 md:pt-32 md:pb-24",children:(0,n.jsxs)("div",{className:"grid grid-cols-1 md:grid-cols-12 gap-8 items-center",children:[(0,n.jsxs)("div",{className:"md:col-span-7 space-y-6",children:[(0,n.jsxs)(s.E.div,{initial:{opacity:0,y:20},animate:{opacity:1,y:0},transition:{duration:.5},children:[(0,n.jsxs)("h1",{className:"text-4xl md:text-5xl lg:text-6xl font-bold tracking-tight",children:["DevOps & Data Science Engineer  ",(0,n.jsx)("span",{className:"text-primary",children:"|"})," Bridging Models to Production"]}),(0,n.jsx)("p",{className:"mt-4 text-xl text-muted-foreground",children:"Empowered by DevOps Principles for Scalable Deployments"}),(0,n.jsx)("p",{className:"mt-6 text-xl text-muted-foreground max-w-2xl",children:"As a Data Scientist by education, I'm passionate about extracting meaningful insights from complex data and building predictive models. My hands-on experience in DevOps and self-hosting allows me to bridge the gap between model development and production, ensuring data-driven solutions are efficiently deployed, monitored, and maintained."})]}),(0,n.jsxs)(s.E.div,{className:"pt-4 flex flex-wrap gap-4",initial:{opacity:0,y:20},animate:{opacity:1,y:0},transition:{duration:.5,delay:.2},children:[(0,n.jsx)(o.z,{size:"lg",asChild:!0,children:(0,n.jsx)(h(),{href:"/projects",children:"Explore My Data Science Projects"})}),(0,n.jsx)(o.z,{size:"lg",variant:"outline",asChild:!0,children:(0,n.jsx)(h(),{href:"/homelab",children:"View My DevOps Infrastructure"})}),(0,n.jsx)(o.z,{size:"lg",variant:"ghost",asChild:!0,children:(0,n.jsx)("a",{href:"https://linkedin.com/",target:"_blank",rel:"noopener noreferrer",children:"Connect on LinkedIn"})})]})]}),(0,n.jsx)("div",{className:"md:col-span-5",children:(0,n.jsx)(s.E.div,{initial:{opacity:0,scale:.9},animate:{opacity:1,scale:1},transition:{duration:.5,delay:.3},className:"relative h-[300px] md:h-[400px] bg-background/40 backdrop-blur-sm rounded-lg p-8 border",children:(0,n.jsxs)("div",{className:"flex flex-col h-full justify-center items-center",children:[(0,n.jsx)("div",{className:"absolute inset-0 flex items-center justify-center opacity-10",children:g.map((t,i)=>(0,n.jsx)("div",{className:"absolute",style:{opacity:i===e?.7:.1},children:t.icon},i))}),(0,n.jsxs)(s.E.div,{initial:{opacity:0,y:20},animate:{opacity:1,y:0},exit:{opacity:0,y:-20},transition:{duration:.3},className:"flex flex-col items-center justify-center ".concat(g[e].color),children:[(0,n.jsx)("div",{className:"text-4xl mb-4",children:g[e].icon}),(0,n.jsx)("p",{className:"text-xl font-medium",children:g[e].name})]},e)]})})})]})})]})}},31618:function(e,t,i){"use strict";i.r(t),i.d(t,{default:function(){return g}});var n=i(2070),a=i(24245),o=i.n(a),s=i(31227),r=i.n(s),l=i(79752),c=i(85078),d=i(68596),m=i(1076),u=i(26316),p=i(42376);function h(e){let{project:t,index:i}=e;return(0,n.jsxs)(l.E.div,{initial:{opacity:0,y:20},whileInView:{opacity:1,y:0},transition:{duration:.5,delay:.1*i},viewport:{once:!0},className:"group relative overflow-hidden rounded-lg border bg-card shadow-sm transition-all hover:shadow-md",children:[(0,n.jsxs)("div",{className:"aspect-video relative overflow-hidden",children:[(0,n.jsx)(r(),{src:t.imageSrc,alt:t.title,fill:!0,className:"object-cover transition-transform duration-300 group-hover:scale-105"}),(0,n.jsx)("div",{className:"absolute inset-0 bg-gradient-to-t from-background/80 to-transparent"})]}),(0,n.jsxs)("div",{className:"p-6",children:[(0,n.jsx)("h3",{className:"text-xl font-semibold tracking-tight mb-2",children:t.title}),(0,n.jsx)("p",{className:"text-muted-foreground text-sm mb-4",children:t.shortDescription}),(0,n.jsxs)("div",{className:"flex flex-wrap gap-2 mb-4",children:[t.technologies.slice(0,3).map(e=>(0,n.jsx)("span",{className:"inline-flex items-center rounded-md bg-primary/10 px-2 py-1 text-xs font-medium text-primary",children:e},e)),t.technologies.length>3&&(0,n.jsxs)("span",{className:"inline-flex items-center rounded-md bg-muted px-2 py-1 text-xs font-medium",children:["+",t.technologies.length-3," more"]})]}),(0,n.jsxs)("div",{className:"flex items-center justify-between mt-4",children:[(0,n.jsx)(c.z,{asChild:!0,variant:"ghost",size:"sm",children:(0,n.jsxs)(o(),{href:"/projects/".concat(t.slug),children:["View Details ",(0,n.jsx)(d.Z,{className:"ml-2 h-4 w-4"})]})}),(0,n.jsxs)("div",{className:"flex items-center gap-2",children:[t.githubUrl&&(0,n.jsx)(c.z,{asChild:!0,variant:"ghost",size:"icon",children:(0,n.jsx)("a",{href:t.githubUrl,target:"_blank",rel:"noopener noreferrer","aria-label":"GitHub Repository",children:(0,n.jsx)(m.Z,{className:"h-4 w-4"})})}),t.liveUrl&&(0,n.jsx)(c.z,{asChild:!0,variant:"ghost",size:"icon",children:(0,n.jsx)("a",{href:t.liveUrl,target:"_blank",rel:"noopener noreferrer","aria-label":"Live Demo",children:(0,n.jsx)(u.Z,{className:"h-4 w-4"})})})]})]})]})]})}function g(){let e=p.q.slice(0,3);return(0,n.jsx)("section",{className:"py-16 md:py-24",children:(0,n.jsxs)("div",{className:"container",children:[(0,n.jsxs)("div",{className:"flex flex-col md:flex-row md:items-center md:justify-between mb-12",children:[(0,n.jsxs)(l.E.div,{initial:{opacity:0,y:20},whileInView:{opacity:1,y:0},transition:{duration:.5},viewport:{once:!0},className:"max-w-2xl",children:[(0,n.jsx)("h2",{className:"text-3xl font-bold tracking-tight mb-3",children:"Featured Projects"}),(0,n.jsx)("p",{className:"text-muted-foreground",children:"A selection of my recent DevOps and self-hosting projects, showcasing my skills and experience."})]}),(0,n.jsx)(c.z,{asChild:!0,variant:"outline",className:"mt-4 md:mt-0",children:(0,n.jsxs)(o(),{href:"/projects",children:["View All Projects ",(0,n.jsx)(d.Z,{className:"ml-2 h-4 w-4"})]})})]}),(0,n.jsx)("div",{className:"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6",children:e.map((e,t)=>(0,n.jsx)(h,{project:e,index:t},e.id))})]})})}},77341:function(e,t,i){"use strict";i.r(t),i.d(t,{default:function(){return u}});var n=i(2070),a=i(79752),o=i(65516),s=i(6776),r=i(15179),l=i(42376),c=i(30814);let d=e=>{let t=s[e.charAt(0).toUpperCase()+e.slice(1)];return t||r.Z};function m(e){let{title:t,icon:i,description:s,technologies:r,className:l}=e;return(0,n.jsxs)(a.E.div,{initial:{opacity:0,y:20},whileInView:{opacity:1,y:0},transition:{duration:.5},viewport:{once:!0,amount:.2},className:(0,o.cn)("rounded-lg border bg-card p-6 shadow-sm",l),children:[(0,n.jsxs)("div",{className:"flex items-center gap-3 mb-4",children:[i," ",(0,n.jsx)("h3",{className:"font-semibold text-lg",children:t})]}),(0,n.jsx)("p",{className:"text-muted-foreground text-sm mb-4",children:s}),(0,n.jsx)("div",{className:"flex flex-wrap gap-2",children:r.map(e=>(0,n.jsx)("span",{className:"inline-flex items-center rounded-md bg-muted px-3 py-1 text-sm font-medium text-foreground",children:e},e))})]})}function u(){let e=l.gd.map(e=>({...e,technologies:l.RJ.filter(t=>t.category===e.key).map(e=>e.name)}));return(0,n.jsx)("section",{id:"skills",className:"py-16 md:py-24 bg-muted/50",children:(0,n.jsxs)("div",{className:"container",children:[(0,n.jsx)("div",{className:"text-center max-w-2xl mx-auto mb-12",children:(0,n.jsxs)(a.E.div,{initial:{opacity:0,y:20},whileInView:{opacity:1,y:0},transition:{duration:.5},viewport:{once:!0},children:[(0,n.jsx)("h2",{className:"text-3xl font-bold tracking-tight mb-4",children:"My Technical Stack"}),(0,n.jsx)("p",{className:"text-muted-foreground text-lg",children:"As a **DevOps cum Data Science Engineer**, I bridge the gap between insightful data models and robust production systems. Here's a look at the technologies empowering my work."})]})}),(0,n.jsx)("div",{className:"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6",children:e.map(e=>{let t=d(e.icon),i="text-gray-500";switch(e.key){case"machine-learning":i="text-purple-500";break;case"data-engineering":i="text-blue-500";break;case"analytics":i="text-green-500";break;case"mlops":i="text-red-500";break;case"cloud":i="text-sky-500";break;case"networking":i="text-orange-500";break;case"security":i="text-indigo-500";break;case"observability":i="text-yellow-500";break;default:i="text-gray-500"}return(0,n.jsx)(m,{title:e.name,icon:t&&c.createElement(t,{className:(0,o.cn)("h-6 w-6",i)}),technologies:e.technologies,description:""},e.key)})})]})})}},85078:function(e,t,i){"use strict";i.d(t,{z:function(){return c}});var n=i(2070),a=i(30814),o=i(94985),s=i(71057),r=i(65516);let l=(0,s.j)("inline-flex items-center justify-center whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50",{variants:{variant:{default:"bg-primary text-primary-foreground hover:bg-primary/90",destructive:"bg-destructive text-destructive-foreground hover:bg-destructive/90",outline:"border border-input bg-background hover:bg-accent hover:text-accent-foreground",secondary:"bg-secondary text-secondary-foreground hover:bg-secondary/80",ghost:"hover:bg-accent hover:text-accent-foreground",link:"text-primary underline-offset-4 hover:underline"},size:{default:"h-10 px-4 py-2",sm:"h-9 rounded-md px-3",lg:"h-11 rounded-md px-8",icon:"h-10 w-10"}},defaultVariants:{variant:"default",size:"default"}}),c=a.forwardRef((e,t)=>{let{className:i,variant:a,size:s,asChild:c=!1,...d}=e,m=c?o.g7:"button";return(0,n.jsx)(m,{className:(0,r.cn)(l({variant:a,size:s,className:i})),ref:t,...d})});c.displayName="Button"},42376:function(e,t,i){"use strict";i.d(t,{RJ:function(){return n},gd:function(){return a},q:function(){return o}});let n=[{name:"PyTorch",icon:"brain",category:"machine-learning"},{name:"Scikit-learn",icon:"robot",category:"machine-learning"},{name:"Pandas",icon:"table",category:"data-engineering"},{name:"NumPy",icon:"calculator",category:"data-engineering"},{name:"PostgreSQL",icon:"database",category:"data-engineering"},{name:"Tableau",icon:"pie-chart",category:"analytics"},{name:"Looker Studio",icon:"line-chart",category:"analytics"},{name:"Jupyter",icon:"notebook",category:"analytics"},{name:"Github Actions",icon:"git-branch",category:"mlops"},{name:"Helm",icon:"ship",category:"mlops"},{name:"Docker",icon:"package",category:"mlops"},{name:"Kubernetes",icon:"box",category:"cloud"},{name:"GCP",icon:"cloud",category:"cloud"},{name:"Rancher",icon:"cow",category:"mlops"},{name:"Nginx",icon:"server",category:"networking"},{name:"Traefik",icon:"exchange",category:"networking"},{name:"WireGuard",icon:"shield",category:"networking"},{name:"Grafana",icon:"layout-dashboard",category:"observability"},{name:"Prometheus",icon:"gauge",category:"observability"},{name:"Cloudflare DNS",icon:"globe",category:"security"},{name:"Cloudflare Zero Trust",icon:"lock",category:"security"},{name:"Google OAuth",icon:"key",category:"security"}],a=[{name:"Machine Learning",key:"machine-learning",icon:"brain"},{name:"Data Engineering",key:"data-engineering",icon:"server"},{name:"Analytics & Visualization",key:"analytics",icon:"bar-chart-2"},{name:"MLOps & DevOps",key:"mlops",icon:"cog"},{name:"Cloud Platforms",key:"cloud",icon:"cloud"},{name:"Networking & Proxy",key:"networking",icon:"network"},{name:"Security & Access Management",key:"security",icon:"shield"},{name:"Observability & Monitoring",key:"observability",icon:"eye"}],o=[{id:"1",title:"CI/CD Pipeline with GitHub Actions",slug:"ci-cd-pipeline",shortDescription:"Automated deployment pipeline for a web application using GitHub Actions and Digital Ocean.",longDescription:"Implemented a continuous integration and continuous deployment pipeline for a React application using GitHub Actions. The pipeline builds, tests, and deploys the application to Digital Ocean droplets whenever changes are pushed to the main branch.",technologies:["GitHub Actions","traefik","Docker","Helm"],imageSrc:"https://images.pexels.com/photos/546819/pexels-photo-546819.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1",githubUrl:"https://github.com/vishvesh11/ci-cd-pipeline",problem:"The development team was manually deploying updates to the production environment, which was time-consuming and prone to human error.",solution:"Designed and implemented an automated CI/CD pipeline using GitHub Actions that builds, tests, and deploys the application to Digital Ocean whenever changes are pushed to the main branch.",architecture:"The pipeline consists of several stages: checkout, install dependencies, run tests, build Docker image, push to registry, and deploy to Digital Ocean droplets.",challenges:["Ensuring zero-downtime deployments","Configuring proper environment variables across different environments","Optimizing build times to reduce pipeline duration"],outcomes:["Reduced deployment time from 45 minutes to 8 minutes","99.9% uptime since implementation","Eliminated manual deployment errors","Improved developer productivity by 25%"]},{id:"2",title:"Self-Hosted Smart Home Infrastructure",slug:"smart-home-infrastructure",shortDescription:"Comprehensive smart home system with Home Assistant, custom automations, and monitoring.",longDescription:"Designed and implemented a fully self-hosted smart home system based on Home Assistant, with custom automations, monitoring, and integration with various smart devices. The system runs on a Proxmox virtual environment with high availability and automated backups.",technologies:["Proxmox","Home Assistant","MQTT","Grafana","Prometheus"],imageSrc:"https://images.pexels.com/photos/1643383/pexels-photo-1643383.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1",githubUrl:"https://github.com/vishvesh11/self-hosting-guides",problem:"Off-the-shelf smart home solutions lacked flexibility, had privacy concerns, and didn't offer the level of customization needed.",solution:"Built a custom smart home infrastructure using open-source software running on self-hosted hardware, with comprehensive monitoring and automated failover.",architecture:"The system is centered around Home Assistant running in a Docker container, with  for complex automations, an MQTT broker for device communication, and Grafana/Prometheus for monitoring.",challenges:["Ensuring high availability with proper failover mechanisms","Optimizing resource usage on limited hardware","Implementing secure remote access without exposing services directly to the internet"],outcomes:["Achieved 99.8% system uptime over 12 months","Reduced power consumption by 15% through smart automations","Integrated 25+ IoT devices from different manufacturers into a single control interface","Implemented automated backup system with 3-2-1 strategy"]},{id:"3",title:"Kubernetes Cluster for Homelab",slug:"kubernetes-homelab",shortDescription:"A multi-node Kubernetes cluster for hosting homelab services with automated monitoring.",longDescription:"Designed and implemented a production-grade Kubernetes cluster for homelab use, including high availability, persistent storage, automated monitoring, and GitOps-based deployment.",technologies:["Kubernetes","Prometheus","Grafana","Helm"],imageSrc:"https://images.pexels.com/photos/325229/pexels-photo-325229.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1",githubUrl:"https://github.com/vishvesh11/k8s-homelab",problem:"Managing multiple Docker containers across different machines was becoming complex and difficult to maintain.",solution:"Implemented a Kubernetes cluster to centralize management, improve scalability, and enable automated deployments of homelab services.",architecture:"The cluster consists of three control plane nodes and five worker nodes, with Longhorn for distributed storage, MetalLB for load balancing, and Cert-Manager for TLS certificates.",challenges:["Designing a proper network architecture","Implementing persistent storage for stateful applications","Ensuring high availability with proper resource allocation"],outcomes:["Reduced service deployment time from hours to minutes","Improved resource utilization by 40%","Achieved 99.95% uptime for critical services","Simplified management of 20+ applications"]},{id:"4",title:"City Traffic Dashboard",slug:"realtime-analytics-dashboard",shortDescription:"A dynamic and interactive Dash application designed for exploratory data analysis (EDA) of futuristic city traffic data",longDescription:"This dashboard offers comprehensive insights through the following interactive visualizations Interactive Filters, Speed vs. Traffic Density Scatter Plot, Average Energy Consumption by Economic Condition, etc.",technologies:["Dash (plotly","Pandas","Gunicorn"],imageSrc:"https://images.pexels.com/photos/5380642/pexels-photo-5380642.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1",githubUrl:"https://github.com/vishvesh11/network-security",problem:"Lack of visibility into city traffic",solution:"A dynamic and interactive Dash application designed for exploratory data analysis (EDA) of futuristic city traffic data. The dashboard provides insights into various aspects of urban mobility, including speed, traffic density, energy consumption, and their correlations with factors like economic condition, weather, and day of the week.",architecture:"The application is containerized using Docker and deployed on a Kubernetes cluster, demonstrating a robust and scalable hybrid cloud deployment strategy.",challenges:["Handling the large volume of data and managing it efficiently","Configuring Kuberneties to ensuer CI-CD pipeline","Ensuering auto Issuance of SSL certificate from Lets-encrypt"],outcomes:["An interactive dashboard with all the relavent data displayed entuitively","Gained comprehensive understanding of Github Actions and Kuberneties","Identified and remediated previously unknown security vulnerabilities"]},{id:"5",title:"Machine Learning Model Deployment Pipeline",slug:"ml-deployment-pipeline",shortDescription:"End-to-end MLOps pipeline for model training, validation, and deployment using Kubeflow.",longDescription:"Built a comprehensive MLOps pipeline that automates the entire machine learning lifecycle from data ingestion to model deployment, including automated retraining and monitoring.",technologies:["Kubeflow","MLflow","TensorFlow","Docker","Kubernetes","Prometheus"],imageSrc:"https://images.pexels.com/photos/8386440/pexels-photo-8386440.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1",githubUrl:"https://github.com/vishvesh11/ml-pipeline",problem:"Manual model deployment process was slow, error-prone, and lacked proper monitoring and versioning.",solution:"Implemented an automated MLOps pipeline using Kubeflow for orchestration, MLflow for experiment tracking, and Kubernetes for scalable deployment.",architecture:"The pipeline includes data validation, model training, hyperparameter tuning, model validation, deployment, and monitoring components all orchestrated through Kubeflow.",challenges:["Integrating multiple ML tools into a cohesive pipeline","Implementing proper model versioning and rollback mechanisms","Setting up comprehensive monitoring for model performance drift"],outcomes:["Reduced model deployment time from weeks to hours","Implemented automated model retraining based on performance metrics","Achieved 99.5% model availability with automated failover","Improved model accuracy by 15% through systematic experimentation"]},{id:"6",title:"Real-time Data Analytics Dashboard",slug:"realtime-analytics-dashboard",shortDescription:"Real-time analytics platform processing streaming data with Apache Kafka and Apache Spark.",longDescription:"Developed a real-time analytics platform that processes streaming data from multiple sources, performs real-time analysis, and presents insights through interactive dashboards.",technologies:["Apache Kafka","Apache Spark","Elasticsearch","Kibana","Python","Docker"],imageSrc:"https://images.pexels.com/photos/590022/pexels-photo-590022.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1",githubUrl:"https://github.com/vishvesh11/realtime-analytics",liveUrl:"https://analytics-demo.example.com",problem:"Business needed real-time insights from multiple data sources but existing batch processing was too slow for decision-making.",solution:"Built a streaming analytics platform using Kafka for data ingestion, Spark for real-time processing, and Elasticsearch/Kibana for visualization.",architecture:"Data flows from multiple sources into Kafka topics, Spark Streaming processes the data in real-time, results are stored in Elasticsearch, and Kibana provides interactive dashboards.",challenges:["Handling high-volume streaming data without data loss","Implementing complex event processing for real-time analytics","Ensuring low-latency processing while maintaining data accuracy"],outcomes:["Reduced time-to-insight from hours to seconds","Processed over 1 million events per minute with sub-second latency","Enabled real-time decision making for business operations","Improved operational efficiency by 30% through real-time monitoring"]}]},65516:function(e,t,i){"use strict";i.d(t,{cn:function(){return o}});var n=i(62856),a=i(87660);function o(){for(var e=arguments.length,t=Array(e),i=0;i<e;i++)t[i]=arguments[i];return(0,a.m6)((0,n.W)(t))}}},function(e){e.O(0,[257,129,752,245,430,956,392,610,744],function(){return e(e.s=999)}),_N_E=e.O()}]);